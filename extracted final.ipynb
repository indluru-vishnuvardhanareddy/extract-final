{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e8f7132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b46dc5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>HGT_prl</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>TMP_prl</th>\n",
       "      <th>TMP_2m</th>\n",
       "      <th>APCP_sfc</th>\n",
       "      <th>UGRD_10m</th>\n",
       "      <th>VGRD_10m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990-01-01 00:00:00</td>\n",
       "      <td>5851.0586</td>\n",
       "      <td>13.68</td>\n",
       "      <td>80.16</td>\n",
       "      <td>289.79260</td>\n",
       "      <td>298.78370</td>\n",
       "      <td>1.409983e-14</td>\n",
       "      <td>-0.730697</td>\n",
       "      <td>0.115279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990-01-01 06:00:00</td>\n",
       "      <td>5856.1550</td>\n",
       "      <td>13.68</td>\n",
       "      <td>80.16</td>\n",
       "      <td>288.84174</td>\n",
       "      <td>298.66785</td>\n",
       "      <td>2.255973e-13</td>\n",
       "      <td>-3.830207</td>\n",
       "      <td>-1.373627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990-01-01 12:00:00</td>\n",
       "      <td>5853.1550</td>\n",
       "      <td>13.68</td>\n",
       "      <td>80.16</td>\n",
       "      <td>289.89853</td>\n",
       "      <td>299.04560</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-4.528024</td>\n",
       "      <td>-1.926858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990-01-01 18:00:00</td>\n",
       "      <td>5848.7900</td>\n",
       "      <td>13.68</td>\n",
       "      <td>80.16</td>\n",
       "      <td>288.81348</td>\n",
       "      <td>298.87085</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-4.498979</td>\n",
       "      <td>-0.072557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990-01-02 00:00:00</td>\n",
       "      <td>5851.9550</td>\n",
       "      <td>13.68</td>\n",
       "      <td>80.16</td>\n",
       "      <td>288.18890</td>\n",
       "      <td>299.14282</td>\n",
       "      <td>6.250000e-02</td>\n",
       "      <td>-2.182430</td>\n",
       "      <td>-1.781631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time    HGT_prl  latitude  longitude    TMP_prl     TMP_2m  \\\n",
       "0  1990-01-01 00:00:00  5851.0586     13.68      80.16  289.79260  298.78370   \n",
       "1  1990-01-01 06:00:00  5856.1550     13.68      80.16  288.84174  298.66785   \n",
       "2  1990-01-01 12:00:00  5853.1550     13.68      80.16  289.89853  299.04560   \n",
       "3  1990-01-01 18:00:00  5848.7900     13.68      80.16  288.81348  298.87085   \n",
       "4  1990-01-02 00:00:00  5851.9550     13.68      80.16  288.18890  299.14282   \n",
       "\n",
       "       APCP_sfc  UGRD_10m  VGRD_10m  \n",
       "0  1.409983e-14 -0.730697  0.115279  \n",
       "1  2.255973e-13 -3.830207 -1.373627  \n",
       "2  0.000000e+00 -4.528024 -1.926858  \n",
       "3  0.000000e+00 -4.498979 -0.072557  \n",
       "4  6.250000e-02 -2.182430 -1.781631  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\vishn\\\\Downloads\\\\extracted_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c768e8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_factor = 10**3  # Convert meters to millimeters\n",
    "df['APCP_sfc'] = (df['APCP_sfc'] * scaling_factor).round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "205683f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(prediction, actual,  mean_dims = ('time')):\n",
    "  error = prediction - actual\n",
    "  rmse = np.sqrt(((error)**2 ).mean(mean_dims))\n",
    "  return rmse\n",
    "def compute_mae(prediction, actual, mean_dims = ('time')):\n",
    "    error = prediction - actual\n",
    "    mae = np.abs(error).mean(mean_dims)\n",
    "    return mae\n",
    "def compute_acc(prediction, actual):\n",
    "    clim = actual.mean('time')\n",
    "    try:\n",
    "        t = np.intersect1d(prediction.time, actual.time)\n",
    "        pred_anomaly = prediction.sel(time=t) - clim\n",
    "    except AttributeError:\n",
    "        t = actual.time.values\n",
    "        pred_anomaly = prediction - clim\n",
    "    act_anomaly = actual.sel(time=t) - clim\n",
    "\n",
    "    pred_norm = pred_anomaly - pred_anomaly.mean()\n",
    "    act_norm = act_anomaly - act_anomaly.mean()\n",
    "\n",
    "    acc = (\n",
    "            np.sum(pred_norm * act_norm) /\n",
    "            np.sqrt(\n",
    "                np.sum(pred_norm ** 2) * np.sum(act_norm ** 2)\n",
    "            )\n",
    "    )\n",
    "    return acc\n",
    "def compute_r_square(prediction, actual, mean_dims=('time')):\n",
    "    # Calculate the mean of the actual values along the specified dimensions\n",
    "    actual_mean = actual.mean(mean_dims)\n",
    "\n",
    "    # Calculate the total sum of squares (SS_tot)\n",
    "    ss_tot = ((actual - actual_mean) ** 2).sum(mean_dims)\n",
    "\n",
    "    # Calculate the residual sum of squares (SS_res)\n",
    "    ss_res = ((prediction - actual) ** 2).sum(mean_dims)\n",
    "\n",
    "    # Calculate R-squared\n",
    "    r_square = 1 - (ss_res / ss_tot)\n",
    "\n",
    "    return r_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9a3b3866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: X_train=(39413, 28, 1), y_train=(39413, 8)\n",
      "Validation data shape: X_valid=(2885, 28, 1), y_valid=(2885, 8)\n",
      "Test data shape: X_test=(1425, 28, 1), y_test=(1425, 8)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Filter the data by year (assuming 'time' column exists)\n",
    "train_data = df[(df['time'] >= '1990') & (df['time'] < '2017')].drop(columns=['time'])\n",
    "valid_data = df[(df['time'] >= '2017') & (df['time'] < '2019')].drop(columns=['time'])\n",
    "test_data = df[(df['time'] >= '2019') & (df['time'] <= '2020')].drop(columns=['time'])\n",
    "\n",
    "# Define features and target variables\n",
    "#features = ['HGT_prl', 'TMP_2m', 'APCP_sfc', 'UGRD_10m', 'VGRD_10m']  # Example feature columns\n",
    "features = ['UGRD_10m'] \n",
    "target = 'UGRD_10m'  # Example target column\n",
    "\n",
    "# Split features and target variable\n",
    "train_features = train_data[features]\n",
    "train_target = train_data[target]\n",
    "valid_features = valid_data[features]\n",
    "valid_target = valid_data[target]\n",
    "test_features = test_data[features]\n",
    "test_target = test_data[target]\n",
    "\n",
    "# Normalize the features using the mean and standard deviation of the training data\n",
    "scaler = StandardScaler()\n",
    "train_features_scaled = scaler.fit_transform(train_features)\n",
    "valid_features_scaled = scaler.transform(valid_features)\n",
    "test_features_scaled = scaler.transform(test_features)\n",
    "\n",
    "# Function to create windowed data\n",
    "def create_windowed_data(features_data, target_data, past_steps, future_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(features_data) - past_steps - future_steps + 1):\n",
    "        X.append(features_data[i:i + past_steps])\n",
    "        y.append(target_data[i + past_steps:i + past_steps + future_steps])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Parameters\n",
    "past_steps = 28\n",
    "future_steps = 8\n",
    "\n",
    "# Create windowed data for each dataset\n",
    "X_train, y_train = create_windowed_data(train_features_scaled, train_target.values, past_steps, future_steps)\n",
    "X_valid, y_valid = create_windowed_data(valid_features_scaled, valid_target.values, past_steps, future_steps)\n",
    "X_test, y_test = create_windowed_data(test_features_scaled, test_target.values, past_steps, future_steps)\n",
    "\n",
    "# Now X_train, y_train, X_valid, y_valid, X_test, y_test are ready for model training and evaluation\n",
    "print(f\"Training data shape: X_train={X_train.shape}, y_train={y_train.shape}\")\n",
    "print(f\"Validation data shape: X_valid={X_valid.shape}, y_valid={y_valid.shape}\")\n",
    "print(f\"Test data shape: X_test={X_test.shape}, y_test={y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d577f8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Model, Sequential\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import MeanAbsoluteError\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Conv1D, LSTM, Lambda, Reshape, RNN, GRU, LSTMCell\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Bidirectional, LSTM, Dense, TimeDistributed, Conv1D, MaxPooling1D, Dropout, Conv3D\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "02a32ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1232/1232 [==============================] - 14s 11ms/step - loss: 7.1437 - val_loss: 6.2814\n",
      "Epoch 2/10\n",
      "1232/1232 [==============================] - 13s 11ms/step - loss: 6.8790 - val_loss: 6.0948\n",
      "Epoch 3/10\n",
      "1232/1232 [==============================] - 13s 10ms/step - loss: 4.3400 - val_loss: 3.1130\n",
      "Epoch 4/10\n",
      "1232/1232 [==============================] - 13s 10ms/step - loss: 3.5299 - val_loss: 2.9723\n",
      "Epoch 5/10\n",
      "1232/1232 [==============================] - 13s 11ms/step - loss: 3.3971 - val_loss: 2.9963\n",
      "Epoch 6/10\n",
      "1232/1232 [==============================] - 13s 11ms/step - loss: 3.2966 - val_loss: 2.9819\n",
      "Epoch 7/10\n",
      "1232/1232 [==============================] - 13s 11ms/step - loss: 3.2048 - val_loss: 3.0007\n",
      "Epoch 8/10\n",
      "1232/1232 [==============================] - 13s 11ms/step - loss: 3.1250 - val_loss: 3.0449\n",
      "Epoch 9/10\n",
      "1232/1232 [==============================] - 13s 11ms/step - loss: 3.0565 - val_loss: 3.0290\n",
      "Epoch 10/10\n",
      "1232/1232 [==============================] - 13s 11ms/step - loss: 2.9784 - val_loss: 3.1494\n",
      "45/45 [==============================] - 0s 3ms/step\n",
      "R-squared: 0.6058388943865008\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_30 (Conv1D)          (None, 26, 64)            256       \n",
      "                                                                 \n",
      " max_pooling1d_18 (MaxPoolin  (None, 13, 64)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_31 (Conv1D)          (None, 11, 128)           24704     \n",
      "                                                                 \n",
      " conv1d_32 (Conv1D)          (None, 9, 256)            98560     \n",
      "                                                                 \n",
      " max_pooling1d_19 (MaxPoolin  (None, 4, 256)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 8)                 2056      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 781,704\n",
      "Trainable params: 781,704\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define the number of features\n",
    "num_features = X_train.shape[2]  # Number of features in your data\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(past_steps, num_features)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "# Adjust the output layer to match the shape of y_train\n",
    "model.add(Dense(future_steps)) # Output a single value for each time step\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_valid, y_valid))\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Reshape predictions to match y_test shape if necessary\n",
    "# y_pred = y_pred.reshape(y_test.shape)\n",
    "\n",
    "# Calculate R-squared value\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test.flatten(), y_pred.flatten())\n",
    "\n",
    "print(f'R-squared: {r2}')\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eedf9b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 3ms/step\n",
      "RMSE: 1.7817063899158627\n",
      "MAE: 1.32574660294333\n",
      "ACC: 0.7932782920623473\n",
      "R2: 0.6058388943865008\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def compute_rmse(prediction, actual):\n",
    "    error = prediction - actual\n",
    "    rmse = np.sqrt((error**2).mean())\n",
    "    return rmse\n",
    "\n",
    "def compute_mae(prediction, actual):\n",
    "    error = prediction - actual\n",
    "    mae = np.abs(error).mean()\n",
    "    return mae\n",
    "\n",
    "def compute_acc(prediction, actual):\n",
    "    # Calculate climatology (mean of actual values)\n",
    "    clim = actual.mean(axis=0)\n",
    "\n",
    "    # Calculate anomalies (difference from the climatology)\n",
    "    pred_anomaly = prediction - clim\n",
    "    act_anomaly = actual - clim\n",
    "\n",
    "    # Normalize the anomalies\n",
    "    pred_norm = pred_anomaly - pred_anomaly.mean(axis=0)\n",
    "    act_norm = act_anomaly - act_anomaly.mean(axis=0)\n",
    "\n",
    "    # Calculate the Anomaly Correlation Coefficient (ACC)\n",
    "    acc = (\n",
    "        np.sum(pred_norm * act_norm) /\n",
    "        np.sqrt(np.sum(pred_norm**2) * np.sum(act_norm**2))\n",
    "    )\n",
    "    return acc\n",
    "\n",
    "def compute_r_square(prediction, actual):\n",
    "    # Calculate R-squared using sklearn's r2_score\n",
    "    r_square = r2_score(actual.flatten(), prediction.flatten())\n",
    "    return r_square\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Compute metrics for the forecast period (output steps)\n",
    "rmse = compute_rmse(y_pred, y_test)\n",
    "mae = compute_mae(y_pred, y_test)\n",
    "acc = compute_acc(y_pred, y_test)\n",
    "r2 = compute_r_square(y_pred, y_test)\n",
    "\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'ACC: {acc}')\n",
    "print(f'R2: {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa25ce97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
